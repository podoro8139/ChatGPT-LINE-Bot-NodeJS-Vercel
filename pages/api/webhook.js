import fetch from "node-fetch";
import { Configuration, OpenAIApi } from "openai";

export default async function handler(req, res) {
  console.log("ğŸŸ¡ğŸŸ¡ğŸŸ¡ Webhookã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«åˆ°é”ï¼");

  if (req.method !== "POST") {
    console.log("âŒ POSTãƒ¡ã‚½ãƒƒãƒ‰ã˜ã‚ƒãªã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæ¥ã¾ã—ãŸï¼");
    return res.status(405).end();
  }

  const body = req.body;
  console.log("ğŸ“¦ ãƒªã‚¯ã‚¨ã‚¹ãƒˆbody:", JSON.stringify(body));

  const userMessage = body.events?.[0]?.message?.text || null;
  const replyToken = body.events?.[0]?.replyToken || null;

  if (!userMessage || !replyToken) {
    console.log("âŒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¾ãŸã¯replyTokenãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“");
    return res.status(400).send("Bad request");
  }

  console.log("ğŸ’¬ å—ä¿¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:", userMessage);

  const configuration = new Configuration({
    apiKey: process.env.OPENAI_API_KEY,
  });
  const openai = new OpenAIApi(configuration);

  let replyText = "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚";

  try {
    const response = await openai.createChatCompletion({
      model: process.env.GPT_MODEL || "gpt-3.5-turbo",
      messages: [{ role: "user", content: userMessage }],
    });

    replyText = response.data.choices[0].message.content;
    console.log("âœ… GPTå¿œç­”:", replyText);
  } catch (error) {
    console.error("ğŸš¨ OpenAIã‚¨ãƒ©ãƒ¼:", error);
  }

  const headers = {
    "Content-Type": "application/json",
    Authorization: `Bearer ${process.env.LINE_CHANNEL_ACCESS_TOKEN}`,
  };

  try {
    const lineRes = await fetch("https://api.line.me/v2/bot/message/reply", {
      method: "POST",
      headers: headers,
      body: JSON.stringify({
        replyToken: replyToken,
        messages: [{ type: "text", text: replyText }],
      }),
    });

    console.log("ğŸ“© LINEè¿”ä¿¡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:", lineRes.status);
  } catch (error) {
    console.error("ğŸš¨ LINEè¿”ä¿¡ã‚¨ãƒ©ãƒ¼:", error);
  }

  return res.status(200).send("OK");
}
