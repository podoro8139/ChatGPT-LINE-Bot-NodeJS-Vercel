import fetch from "node-fetch";
import { Configuration, OpenAIApi } from "openai";
import { buffer } from "micro";

export const config = {
  api: {
    bodyParser: false, // LINE Webhookå¯¾å¿œã®ãŸã‚ç„¡åŠ¹åŒ–
  },
};

export default async function handler(req, res) {
  console.log("ğŸŸ¡ Webhookã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«åˆ°é”");

  if (req.method !== "POST") {
    console.log("âŒ POSTã˜ã‚ƒãªã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæ¥ã¾ã—ãŸ");
    return res.status(405).end();
  }

  try {
    const buf = await buffer(req);
    const bodyText = buf.toString("utf-8");
    const body = JSON.parse(bodyText);
    console.log("ğŸ“© body:", JSON.stringify(body));

    const userMessage = body.events?.[0]?.message?.text || null;
    const replyToken = body.events?.[0]?.replyToken || null;

    if (!userMessage || !replyToken) {
      console.log("âŒ userMessageã‹replyTokenãŒå–å¾—ã§ãã¾ã›ã‚“");
      return res.status(400).send("Bad request");
    }

    console.log("ğŸ“ å—ä¿¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:", userMessage);

    const configuration = new Configuration({
      apiKey: process.env.OPENAI_API_KEY,
    });
    const openai = new OpenAIApi(configuration);

    const response = await openai.createChatCompletion({
      model: process.env.GPT_MODEL || "gpt-3.5-turbo",
      messages: [{ role: "user", content: userMessage }],
    });

    const replyText = response.data.choices[0].message.content;
    console.log("ğŸ¤– GPTå¿œç­”:", replyText);

    const headers = {
      "Content-Type": "application/json",
      Authorization: `Bearer ${process.env.LINE_CHANNEL_ACCESS_TOKEN}`,
    };

    await fetch("https://api.line.me/v2/bot/message/reply", {
      method: "POST",
      headers: headers,
      body: JSON.stringify({
        replyToken: replyToken,
        messages: [{ type: "text", text: replyText }],
      }),
    });

    console.log("âœ… LINEã«è¿”ç­”ã‚’é€ä¿¡ã—ã¾ã—ãŸ");
    return res.status(200).send("OK");
  } catch (err) {
    console.error("ğŸš¨ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ:", err);
    return res.status(500).send("Internal Server Error");
  }
}
