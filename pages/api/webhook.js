// node-fetch ã‚’ä½¿ã£ã¦ fetch ã‚’æœ‰åŠ¹åŒ–ï¼ˆVercelãªã©ã®Node.jsãƒ©ãƒ³ã‚¿ã‚¤ãƒ å¯¾ç­–ï¼‰
import fetch from "node-fetch";
import { Configuration, OpenAIApi } from "openai";

export default async function handler(req, res) {
  // POSTãƒ¡ã‚½ãƒƒãƒ‰ä»¥å¤–ã¯æ‹’å¦
  if (req.method !== "POST") {
    return res.status(405).end();
  }

  const body = req.body;

  // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾—ï¼ˆãªã‘ã‚Œã° "ã“ã‚“ã«ã¡ã¯"ï¼‰
  const userMessage = body.events?.[0]?.message?.text || "ã“ã‚“ã«ã¡ã¯";

  console.log("âœ… LINEã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:", userMessage);

  // OpenAIè¨­å®š
  const configuration = new Configuration({
    apiKey: process.env.OPENAI_API_KEY,
  });
  const openai = new OpenAIApi(configuration);

  try {
    // ChatGPTã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
    const response = await openai.createChatCompletion({
      model: process.env.GPT_MODEL || "gpt-3.5-turbo",
      messages: [{ role: "user", content: userMessage }],
    });

    const replyText = response.data.choices[0].message.content;
    console.log("ğŸ¤– GPTã®è¿”ç­”:", replyText);

    // LINEã«è¿”äº‹ã‚’è¿”ã™
    const headers = {
      "Content-Type": "application/json",
      Authorization: `Bearer ${process.env.LINE_CHANNEL_ACCESS_TOKEN}`,
    };

    const replyPayload = {
      replyToken: body.events[0].replyToken,
      messages: [{ type: "text", text: replyText }],
    };

    const lineResponse = await fetch("https://api.line.me/v2/bot/message/reply", {
      method: "POST",
      headers: headers,
      body: JSON.stringify(replyPayload),
    });

    if (!lineResponse.ok) {
      const errorDetails = await lineResponse.text();
      console.error("ğŸš¨ LINEã¸ã®è¿”ä¿¡ã‚¨ãƒ©ãƒ¼:", errorDetails);
    } else {
      console.log("âœ… LINEã«è¿”äº‹ãŒé€ä¿¡ã•ã‚Œã¾ã—ãŸï¼");
    }

    return res.status(200).send("OK");
  } catch (err) {
    console.error("âŒ ã‚¨ãƒ©ãƒ¼:", err);
    return res.status(500).send("Internal Server Error");
  }
}
