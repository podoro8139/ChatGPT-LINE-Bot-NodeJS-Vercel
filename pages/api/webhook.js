import fetch from "node-fetch";
import { Configuration, OpenAIApi } from "openai";

export default async function handler(req, res) {
  console.log("ğŸŸ¡ Webhookã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«åˆ°é”");

  if (req.method !== "POST") {
    console.log("âŒ POSTã˜ã‚ƒãªã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæ¥ã¾ã—ãŸ");
    return res.status(405).end();
  }

  const body = req.body;
  console.log("ğŸ“¦ body:", JSON.stringify(body));

  const userMessage = body?.events?.[0]?.message?.text || null;
  const replyToken = body?.events?.[0]?.replyToken;

  if (!userMessage || !replyToken) {
    console.log("âŒ userMessage ã‹ replyToken ãŒå–å¾—ã§ãã¾ã›ã‚“");
    return res.status(400).send("Bad request");
  }

  console.log("ğŸ“© å—ä¿¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:", userMessage);

  const configuration = new Configuration({
    apiKey: process.env.OPENAI_API_KEY,
  });
  const openai = new OpenAIApi(configuration);

  try {
    const response = await openai.createChatCompletion({
      model: process.env.GPT_MODEL || "gpt-3.5-turbo",
      messages: [{ role: "user", content: userMessage }],
    });

    const replyText = response.data.choices[0].message.content;
    console.log("ğŸ¤– GPTã®è¿”ç­”:", replyText);

    const headers = {
      "Content-Type": "application/json",
      Authorization: `Bearer ${process.env.LINE_CHANNEL_ACCESS_TOKEN}`,
    };

    const payload = {
      replyToken: replyToken,
      messages: [{ type: "text", text: replyText }],
    };

    const lineRes = await fetch("https://api.line.me/v2/bot/message/reply", {
      method: "POST",
      headers,
      body: JSON.stringify(payload),
    });

    const lineText = await lineRes.text();

    if (!lineRes.ok) {
      console.log("ğŸš¨ LINEè¿”ä¿¡ã‚¨ãƒ©ãƒ¼:", lineText);
    } else {
      console.log("âœ… LINEã«è¿”äº‹ã‚’é€ã‚Šã¾ã—ãŸ");
    }

    return res.status(200).send("OK");
  } catch (err) {
    console.error("âŒ å‡¦ç†ä¸­ã®ã‚¨ãƒ©ãƒ¼:", err);
    return res.status(500).send("Internal Server Error");
  }
}
